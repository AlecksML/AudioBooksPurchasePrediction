{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT: Audio Books' Purchase Prediction.\n",
    "## Project Goal\n",
    " \n",
    "The goal is to create a machine learning algorithm that can predict if a customer will buy again from the Audiobook company.\n",
    "Data is collected from an Audiobook app. Each customer in the database has made a purchase of audio versions of the books atleast once.\n",
    "\n",
    "The main idea is to focus our efforts ONLY on customers that are likely to buy from the company again, in this case we can make great savings. If a customer has a low probability of coming back, it would be wasteful to spend resources advertising to them.\n",
    "\n",
    "There are several variables: 'Customer ID', 'Book length avg' (average of all purchases in minutes), 'Book length sum' (sum of all purchases in minutes), 'Avg Price'(average of all purchases), 'Sum Price paid' (sum of all purchases), 'Review' (a Boolean variable), 'Review(out of 10)', 'Completion' (from 0 to 1) , 'Total minutes listened', 'Support Requests' (number), 'Last visited' (minus purchase date in days), 'Purchase' (targets).\n",
    "\n",
    "The targets are a Boolean variable (so 0, or 1). We are taking a period of 2 years in our inputs, and the next 6 months as targets. So, in fact, we are predicting if: based on the last 2 years of activity and engagement, a customer will convert in the next 6 months. 6 months sounds like a reasonable time. If they don't convert after 6 months, chances are they've gone to a competitor or didn't like the Audiobook way of digesting information. \n",
    "\n",
    "The task is simple: create a machine learning algorithm, which is able to predict if a customer will buy again. \n",
    "\n",
    "This is a classification problem with two classes: won't buy and will buy, represented by 0s and 1s. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "* Preprocess the data.\n",
    "* Balance the dataset. \n",
    "* Create 3 datasets: training, validation, and test. \n",
    "* Save the newly created sets in a tensor friendly format (e.g. *.npz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Book length avg</th>\n",
       "      <th>Book length Sum</th>\n",
       "      <th>Avg Price</th>\n",
       "      <th>Sum Price Paid</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review(out of 10)</th>\n",
       "      <th>Completion</th>\n",
       "      <th>Total Mins Listened</th>\n",
       "      <th>Support Requests</th>\n",
       "      <th>Last Visited(days)</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>994</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>19.73</td>\n",
       "      <td>19.73</td>\n",
       "      <td>1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1603.8</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1143</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2882</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>5.96</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.42</td>\n",
       "      <td>680.4</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3342</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.22</td>\n",
       "      <td>475.2</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Book length avg  Book length Sum  Avg Price  Sum Price Paid  \\\n",
       "0         994           1620.0             1620      19.73           19.73   \n",
       "1        1143           2160.0             2160       5.33            5.33   \n",
       "2        2059           2160.0             2160       5.33            5.33   \n",
       "3        2882           1620.0             1620       5.96            5.96   \n",
       "4        3342           2160.0             2160       5.33            5.33   \n",
       "\n",
       "   Review  Review(out of 10)  Completion  Total Mins Listened  \\\n",
       "0       1              10.00        0.99               1603.8   \n",
       "1       0               8.91        0.00                  0.0   \n",
       "2       0               8.91        0.00                  0.0   \n",
       "3       0               8.91        0.42                680.4   \n",
       "4       0               8.91        0.22                475.2   \n",
       "\n",
       "   Support Requests  Last Visited(days)  Purchase  \n",
       "0                 5                  92         0  \n",
       "1                 0                   0         0  \n",
       "2                 0                 388         0  \n",
       "3                 1                 129         0  \n",
       "4                 0                 361         0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load and read the data provided\n",
    "data = pd.read_csv('AudioBooks-data.csv')\n",
    "#print the first 5 rows of the data to get a picture of how the data looks like\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID             0\n",
       "Book length avg        0\n",
       "Book length Sum        0\n",
       "Avg Price              0\n",
       "Sum Price Paid         0\n",
       "Review                 0\n",
       "Review(out of 10)      0\n",
       "Completion             0\n",
       "Total Mins Listened    0\n",
       "Support Requests       0\n",
       "Last Visited(days)     0\n",
       "Purchase               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for any missing values in the data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data contains no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11847\n",
       "1     2237\n",
       "Name: Purchase, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking total number of counts for each of the target values\n",
    "data['Purchase'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows how unbalanced the data is, so first step is to make sure our data is well balanced to avoid bias in predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14084, 10) (14084,)\n"
     ]
    }
   ],
   "source": [
    "#So these are the inputs (excluding customer ID, as it is completely arbitrary. It's more like a name, than a number).\n",
    "# create arrays for both inputs and targets for easy numpy manipulations\n",
    "inputs = np.array(data.drop(['CustomerID', 'Purchase'], 1))\n",
    "targets = np.array(data.Purchase)\n",
    "print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to balance the given data taking data_inputs and data_targets as parameters\n",
    "def BalanceData(data_inputs, data_targets):\n",
    "    remove_indices = []\n",
    "    count_ones = int(np.sum(data_targets))\n",
    "    count_zeros = 0\n",
    "    for i in range(targets.shape[0]):\n",
    "        if targets[i] == 0:\n",
    "            count_zeros += 1\n",
    "            if count_zeros > count_ones:\n",
    "                remove_indices.append(i)\n",
    "    balanced_inputs = np.delete(data_inputs, remove_indices, axis=0)\n",
    "    balanced_targets = np.delete(data_targets, remove_indices, axis=0)\n",
    "    return balanced_inputs, balanced_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4474, 10) (4474,)\n"
     ]
    }
   ],
   "source": [
    "balanced_inputs, balanced_targets = BalanceData(inputs, targets)\n",
    "print(balanced_inputs.shape, balanced_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21053387 -0.18888517  1.97823887 ...  4.80955413 11.83828419\n",
      "   0.09415043]\n",
      " [ 1.27894497  0.41646744 -0.39082475 ... -0.41569922 -0.20183481\n",
      "  -0.80255852]\n",
      " [ 1.27894497  0.41646744 -0.39082475 ... -0.41569922 -0.20183481\n",
      "   2.979214  ]\n",
      " ...\n",
      " [ 1.27894497  0.41646744 -0.39082475 ... -0.41569922 -0.20183481\n",
      "  -0.7440775 ]\n",
      " [ 0.31737498  1.7482432   0.04679395 ... -0.41569922 -0.20183481\n",
      "  -0.80255852]\n",
      " [ 0.31737498  1.7482432  -0.39082475 ... -0.41569922 -0.20183481\n",
      "  -0.80255852]]\n"
     ]
    }
   ],
   "source": [
    "# standardize the inputs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_inputs = scaler.fit_transform(balanced_inputs)\n",
    "print(scaled_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the data\n",
    "# This will create randomness in the way data is spread and prevent the model from being biased\n",
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "# Use the shuffled indices to shuffle the inputs and targets.\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = balanced_targets[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "#total number of instances used\n",
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "# number of instances used in training\n",
    "train_samples_count = int(0.75*samples_count)\n",
    "# number of instances used for validation\n",
    "validation_samples_count = int(0.15*samples_count)\n",
    "#number of instances used for testing\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "#train data after shuffling\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "# validation data after shuffling\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count + validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count + validation_samples_count]\n",
    "\n",
    "# test data after shuffling\n",
    "test_inputs = shuffled_inputs[train_samples_count + validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count + validation_samples_count:]\n",
    "\n",
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Train, Validation and Test Datasets as .npz files to be used later on in building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('AudioTrainData', inputs = train_inputs, targets = train_targets)\n",
    "np.savez('AudioValidationData', inputs = validation_inputs, targets = validation_targets)\n",
    "np.savez('AudioTestData', inputs = test_inputs, targets = test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
